{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>label</th>\n",
       "      <th>removed_alay</th>\n",
       "      <th>removed_noise</th>\n",
       "      <th>removed_stopwords</th>\n",
       "      <th>text_asli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200</td>\n",
       "      <td>2094</td>\n",
       "      <td>2296</td>\n",
       "      <td>2296</td>\n",
       "      <td>2285</td>\n",
       "      <td>2297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2141</td>\n",
       "      <td>2141</td>\n",
       "      <td>2125</td>\n",
       "      <td>2296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>positif</td>\n",
       "      <td>netral</td>\n",
       "      <td>lagu , corona virus mematikan\\n\\nganas membunu...</td>\n",
       "      <td>lagu , corona virus mematikan\\n\\nganas membunu...</td>\n",
       "      <td>lagu , corona virus mematikan \\n\\n ganas membu...</td>\n",
       "      <td>@kontannews lagu   ,   corona\\n           viru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>86</td>\n",
       "      <td>891</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Label   label                                       removed_alay  \\\n",
       "count       200    2094                                               2296   \n",
       "unique        3       7                                               2141   \n",
       "top     positif  netral  lagu , corona virus mematikan\\n\\nganas membunu...   \n",
       "freq         86     891                                                 28   \n",
       "\n",
       "                                            removed_noise  \\\n",
       "count                                                2296   \n",
       "unique                                               2141   \n",
       "top     lagu , corona virus mematikan\\n\\nganas membunu...   \n",
       "freq                                                   28   \n",
       "\n",
       "                                        removed_stopwords  \\\n",
       "count                                                2285   \n",
       "unique                                               2125   \n",
       "top     lagu , corona virus mematikan \\n\\n ganas membu...   \n",
       "freq                                                   28   \n",
       "\n",
       "                                                text_asli  \n",
       "count                                                2297  \n",
       "unique                                               2296  \n",
       "top     @kontannews lagu   ,   corona\\n           viru...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "\n",
    "path      = r'/home/patrick/Documents/python_project/covid-nlp/new_normal'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "# print(li)\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.id.Indonesian at 0x7f7df03df2e8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "spacy.blank('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.blank('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_dict = {'marah': ['berang', 'gusar', 'terbakar', 'sewot', 'palak', 'membawang', 'tersirap hatinya', 'meraba', 'dendam', 'emosi', 'mencak-mencak', 'rampang', 'dengki', 'berangsang', 'bengis', 'menyangkak', 'didih', 'nafsu', 'radang', 'merah telinga', 'muring', 'gemas', 'makan bawang', 'sirap hati', 'merah', 'meruok', 'geram', 'bertelinga merah', 'benci', 'kecil hati'], \n",
    "                  'sedih': ['duka', 'isak', 'sedu', 'tersentuh (perasaan)', 'muram', 'derita', 'kuyu', 'galaba', 'lara', 'gelebah', 'senak', 'haru', 'larat hati', 'remuk redam', 'gobar hati', 'pedih', 'susah', 'iba', 'terista', 'gundah', 'lemas', 'susah hati', 'masygul', 'benguk', 'berkabut', 'putus tali gantung', 'melankolis', 'dayuh', 'nelangsa', 'enas', 'terdayuh'], \n",
    "                  'senang': ['betah', 'gembira', 'mudah', 'praktis', 'sayang', 'suka', 'tenteram', 'bahagia', 'demen', 'ceria', 'marem', 'ringan', 'sejuk', 'doyan', 'jidur', 'sejuk hati', 'gemar', 'jilah kening', 'girang', 'naim', 'sukacita', 'makmur', 'nikmat', 'aman', 'asyik', 'lapang'], \n",
    "                  'takut': ['gelisah', 'takwa', 'zan', 'berkecil hati', 'lasi', 'bernyali kecil', 'tercemas', 'mamang', 'kecut', 'segan', 'cuak', 'kirik', 'kecut hati', 'bimbang', 'dahsyat', 'gidik', 'keder', 'cemas', 'gemang', 'gamang', 'kimput', 'gentar', 'ciut', 'kecil hati', 'menaruh dahsyat', 'geriap', 'jeri'], \n",
    "                  'khawatir': ['was-was', 'galau', 'waswas', 'berhati walang', 'gamang', 'samar', 'tercemas', 'gelisah', 'risi', 'dura', 'harap-harap cemas', 'berkarut', 'berguncang', 'jeri', 'bimbang', 'terguncang', 'cemas', 'harap-harap'], \n",
    "                  'kesal': ['jemu', 'mendongkol', 'menyebalkan', 'sebal', 'gemas', 'palak', 'penuh perut', 'geram', 'redut', 'salah hati', 'gregetan', 'pegal', 'menjelut', 'gusar', 'benci', 'naik palak', 'bosan', 'bertelinga merah', 'duka', 'masygul']\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>label</th>\n",
       "      <th>removed_alay</th>\n",
       "      <th>removed_noise</th>\n",
       "      <th>removed_stopwords</th>\n",
       "      <th>text_asli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>netral</td>\n",
       "      <td>normal: bukan sungai yang sama\\n\\noleh: bayu k...</td>\n",
       "      <td>normal: bukan sungai yang sama\\n\\noleh: bayu k...</td>\n",
       "      <td>: sungai \\n\\n : bayu krisnamurthi , guru madya...</td>\n",
       "      <td>new normal: bukan sungai yang sama\\n\\noleh: ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positif</td>\n",
       "      <td>from bambang.sunario from wedding \"wiwin &amp;amp;...</td>\n",
       "      <td>from bambang.sunario from wedding \"wiwin &amp;amp;...</td>\n",
       "      <td>from bambang.sunario from wedding \" wiwin &amp; am...</td>\n",
       "      <td>from bambang.sunario from wedding \"wiwin &amp;amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>netral</td>\n",
       "      <td>ya anggep saja üòÅ</td>\n",
       "      <td>ya anggep aja üòÅ</td>\n",
       "      <td>anggep üòÅ</td>\n",
       "      <td>@putriwandaaaa ya anggep aja new normal üòÅ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>netral</td>\n",
       "      <td>normal, car suzuki xl7 !!!\\n.\\n.\\ndapatkan mob...</td>\n",
       "      <td>normal, car suzuki xl7 !!!\\n.\\n.\\ndapatkan mob...</td>\n",
       "      <td>, car suzuki xl7 ! ! ! \\n . \\n . \\n dapatkan m...</td>\n",
       "      <td>new normal, new car suzuki xl7 !!!\\n.\\n.\\ndapa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positif</td>\n",
       "      <td>satuan polisi pamong praja provinsi riau bersa...</td>\n",
       "      <td>satuan polisi pamong praja provinsi riau bersa...</td>\n",
       "      <td>satuan polisi pamong praja provinsi riau dishu...</td>\n",
       "      <td>satuan polisi pamong praja provinsi riau bersa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positif</td>\n",
       "      <td>silakan face shield nya untuk persiapan</td>\n",
       "      <td>silakan face shield nya untuk persiapan</td>\n",
       "      <td>silakan face shield persiapan</td>\n",
       "      <td>silakan face shield nya untuk persiapan new no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>negatif</td>\n",
       "      <td>normal, tujuan utamanya pada kepuncak.\\n\\nkalo...</td>\n",
       "      <td>normal, tujuan utamanya pada kepuncak.\\n\\nkalo...</td>\n",
       "      <td>, tujuan utamanya kepuncak . \\n\\n makan dine m...</td>\n",
       "      <td>new normal, tujuan utamanya pada kepuncak.\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>netral</td>\n",
       "      <td>jadwal dinasan swami sudah mulai senah</td>\n",
       "      <td>jadwal dinasan swami udh mulai senah</td>\n",
       "      <td>jadwal dinasan swami senah</td>\n",
       "      <td>jadwal dinasan swami udh mulai new normal senah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>netral</td>\n",
       "      <td>normal...diskusi diruang gelap.</td>\n",
       "      <td>normal...diskusi diruang gelap.</td>\n",
       "      <td>... diskusi diruang gelap .</td>\n",
       "      <td>@dsimarmata new normal...diskusi diruang gelap.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>positif</td>\n",
       "      <td>normal\\ndiskon besar-besaran khusus dibulan juni‚Ä¶</td>\n",
       "      <td>normal\\ndiskon besar2an khusus dibulan juni‚Ä¶</td>\n",
       "      <td>\\n diskon besar-besaran khusus dibulan juni ‚Ä¶</td>\n",
       "      <td>new normal\\ndiskon besar2an khusus dibulan jun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label    label                                       removed_alay  \\\n",
       "0    NaN   netral  normal: bukan sungai yang sama\\n\\noleh: bayu k...   \n",
       "1    NaN  positif  from bambang.sunario from wedding \"wiwin &amp;...   \n",
       "2    NaN   netral                                   ya anggep saja üòÅ   \n",
       "3    NaN   netral  normal, car suzuki xl7 !!!\\n.\\n.\\ndapatkan mob...   \n",
       "4    NaN  positif  satuan polisi pamong praja provinsi riau bersa...   \n",
       "..   ...      ...                                                ...   \n",
       "95   NaN  positif            silakan face shield nya untuk persiapan   \n",
       "96   NaN  negatif  normal, tujuan utamanya pada kepuncak.\\n\\nkalo...   \n",
       "97   NaN   netral             jadwal dinasan swami sudah mulai senah   \n",
       "98   NaN   netral                    normal...diskusi diruang gelap.   \n",
       "99   NaN  positif  normal\\ndiskon besar-besaran khusus dibulan juni‚Ä¶   \n",
       "\n",
       "                                        removed_noise  \\\n",
       "0   normal: bukan sungai yang sama\\n\\noleh: bayu k...   \n",
       "1   from bambang.sunario from wedding \"wiwin &amp;...   \n",
       "2                                     ya anggep aja üòÅ   \n",
       "3   normal, car suzuki xl7 !!!\\n.\\n.\\ndapatkan mob...   \n",
       "4   satuan polisi pamong praja provinsi riau bersa...   \n",
       "..                                                ...   \n",
       "95            silakan face shield nya untuk persiapan   \n",
       "96  normal, tujuan utamanya pada kepuncak.\\n\\nkalo...   \n",
       "97               jadwal dinasan swami udh mulai senah   \n",
       "98                    normal...diskusi diruang gelap.   \n",
       "99       normal\\ndiskon besar2an khusus dibulan juni‚Ä¶   \n",
       "\n",
       "                                    removed_stopwords  \\\n",
       "0   : sungai \\n\\n : bayu krisnamurthi , guru madya...   \n",
       "1   from bambang.sunario from wedding \" wiwin & am...   \n",
       "2                                            anggep üòÅ   \n",
       "3   , car suzuki xl7 ! ! ! \\n . \\n . \\n dapatkan m...   \n",
       "4   satuan polisi pamong praja provinsi riau dishu...   \n",
       "..                                                ...   \n",
       "95                      silakan face shield persiapan   \n",
       "96  , tujuan utamanya kepuncak . \\n\\n makan dine m...   \n",
       "97                         jadwal dinasan swami senah   \n",
       "98                        ... diskusi diruang gelap .   \n",
       "99      \\n diskon besar-besaran khusus dibulan juni ‚Ä¶   \n",
       "\n",
       "                                            text_asli  \n",
       "0   new normal: bukan sungai yang sama\\n\\noleh: ba...  \n",
       "1   from bambang.sunario from wedding \"wiwin &amp;...  \n",
       "2           @putriwandaaaa ya anggep aja new normal üòÅ  \n",
       "3   new normal, new car suzuki xl7 !!!\\n.\\n.\\ndapa...  \n",
       "4   satuan polisi pamong praja provinsi riau bersa...  \n",
       "..                                                ...  \n",
       "95  silakan face shield nya untuk persiapan new no...  \n",
       "96  new normal, tujuan utamanya pada kepuncak.\\n\\n...  \n",
       "97    jadwal dinasan swami udh mulai new normal senah  \n",
       "98    @dsimarmata new normal...diskusi diruang gelap.  \n",
       "99  new normal\\ndiskon besar2an khusus dibulan jun...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'papers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0100c19a7661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Fit and transform the processed titles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mcount_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpapers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paper_text_processed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Visualise the 10 most common words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'papers' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper function\n",
    "def plot_10_most_common_words(count_data, count_vectorizer):\n",
    "    import matplotlib.pyplot as plt\n",
    "    words        = count_vectorizer.get_feature_names()\n",
    "    total_counts = np.zeros(len(words))\n",
    "    for t in count_data:\n",
    "        total_counts+=t.toarray()[0]\n",
    "    \n",
    "    count_dict = (zip(words, total_counts))\n",
    "    count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)[0:10]\n",
    "    display(count_dict)\n",
    "    words      = [w[0] for w in count_dict]\n",
    "    counts     = [w[1] for w in count_dict]\n",
    "    x_pos      = np.arange(len(words)) \n",
    "    \n",
    "    plt.figure(2, figsize=(15, 15/1.6180))\n",
    "    plt.subplot(title='10 most common words')\n",
    "    sns.set_context(\"notebook\", font_scale=1.25, rc={\"lines.linewidth\": 2.5})\n",
    "    sns.barplot(x_pos, counts, palette='husl')\n",
    "    plt.xticks(x_pos, words, rotation=90) \n",
    "    plt.xlabel('words')\n",
    "    plt.ylabel('counts')\n",
    "    plt.show()\n",
    "\n",
    "# Initialise the count vectorizer with the English stop words\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the processed titles\n",
    "count_data = count_vectorizer.fit_transform(papers['paper_text_processed'])\n",
    "\n",
    "# Visualise the 10 most common words\n",
    "plot_10_most_common_words(count_data, count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'id'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-ea524f6545ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'id'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selamat    \n",
      "-20.0 0 []\n",
      "malam    \n",
      "-20.0 0 []\n",
      "semuanya    \n",
      "-20.0 0 []\n"
     ]
    }
   ],
   "source": [
    "missing_attrs = ['pos_', 'tag_', 'dep_', 'prob', 'cluster', 'vector']\n",
    "doc = nlp('selamat malam semuanya')\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_, token.dep_, token.ent_iob_)\n",
    "    print(token.prob, token.cluster, token.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
